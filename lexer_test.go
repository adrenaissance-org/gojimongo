package gojimongo

import (
	"testing"
	"fmt"
)

func TestLexer(t *testing.T) {
	// Test cases with lexemes and expected tokens
	testCases := map[string][]TokenType{
		"$.store.book": {
			DOLLAR, DOT, IDENTIFIER, DOT, IDENTIFIER,
		},

		"$..author": {
			DOLLAR, RECURSIVE_OP, IDENTIFIER,
		},

		"$['store']['book'][0]['title']": {
			DOLLAR, LBRACK, STRING, RBRACK, LBRACK, STRING, RBRACK, LBRACK, INTEGER, RBRACK, LBRACK, STRING, RBRACK,
		},

		"$.store.book[?(@.price < 10)]": {
			DOLLAR, DOT, IDENTIFIER, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, LT, INTEGER, RPAREN, RBRACK,
		},
		
		"$.store.book[?(@.price <= 10)]": {
			DOLLAR, DOT, IDENTIFIER, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, LTE, INTEGER, RPAREN, RBRACK,
		},

		"$.store.book[?(@.price > 10 && @.author == 'John Doe')]": {
			DOLLAR, DOT, IDENTIFIER, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, GT, INTEGER, AND, AT, DOT, IDENTIFIER, EQEQ, STRING, RPAREN, RBRACK,
		},

		"$.store.book[?(@.author.name == 'John' && @.author.rating > 4)]": {
			DOLLAR, DOT, IDENTIFIER, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, DOT, IDENTIFIER, EQEQ, STRING, AND, AT, DOT, IDENTIFIER, DOT, IDENTIFIER, GT, INTEGER, RPAREN, RBRACK,
		},

		"$..book[*].title": {
			DOLLAR, RECURSIVE_OP, IDENTIFIER, LBRACK, STAR, RBRACK, DOT, IDENTIFIER,
		},

		"$['store'].book[?(@.price > 15)]": {
			DOLLAR, LBRACK, STRING, RBRACK, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, GT, INTEGER, RPAREN, RBRACK,
		},

		"$.store.book[?(@.author == null)]": {
			DOLLAR, DOT, IDENTIFIER, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, EQEQ, NULL, RPAREN, RBRACK,
		},

		"$['weird.key']['complex-@key']": {
			DOLLAR, LBRACK, STRING, RBRACK, LBRACK, STRING, RBRACK, 
		},

		"$.store.book[?(@.price == 0)]": {
			DOLLAR, DOT, IDENTIFIER, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, EQEQ, INTEGER, RPAREN, RBRACK,
		},

		"$..*": {
			DOLLAR, RECURSIVE_OP, STAR,
		},

		"$.store.book[?(@.title == 'She said \"Hello\"')]": {
			DOLLAR, DOT, IDENTIFIER, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, EQEQ, STRING, RPAREN, RBRACK,
		},

		"$..book[?(@.author == 'O\\'Reilly')]": {
			DOLLAR, RECURSIVE_OP, IDENTIFIER, LBRACK, QUESTION_MARK, LPAREN, AT, DOT, IDENTIFIER, EQEQ, STRING, RPAREN, RBRACK,
		},
		"$.books[?@.isbn != null]": {
			DOLLAR, DOT, IDENTIFIER, LBRACK, QUESTION_MARK, AT, DOT, IDENTIFIER, NEQ, NULL, RBRACK,
		},
	}

	// Iterate over the map and print the lexemes and corresponding tokens
	for input, expectedTokens := range testCases {
		fmt.Printf("Testing: %s\n", input)
		lexer := Lexer{}
		err := lexer.Run(input)
		if err != nil {
			fmt.Printf("Error during lexing: %v\n", err)
			continue
		}

		// Compare the tokens generated by the lexer with the expected tokens
		if len(lexer.tokens) != len(expectedTokens) {
			fmt.Printf("Mismatch in number of tokens for: %s\n", input)
			fmt.Printf("%v\n%v\n", lexer.tokens, expectedTokens)
			continue
		}

		for i, token := range lexer.tokens {
			if token != expectedTokens[i] {
				fmt.Printf("Token mismatch at position %d: got %v, expected %v\n", i, token, expectedTokens[i])
				fmt.Printf("%v\n%v\n", lexer.tokens, expectedTokens)
			}
		}
	}
}